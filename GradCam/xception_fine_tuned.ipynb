{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "import timm\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3794d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "train_size = 0.8\n",
    "test_size=0.2\n",
    "cuda = 'cuda'\n",
    "cpu = 'cpu' \n",
    "device = cuda if torch.cuda.is_available() else cpu\n",
    "xception_weight_path = r\"C:\\Users\\SUDARSHAN\\.cache\\torch\\hub\\checkpoints\\xception-43020ad28.pth\"\n",
    "xception_tensorflow_weights = r\"C:\\Users\\SUDARSHAN\\.keras\\models\\xception_weights_tf_dim_ordering_tf_kernels.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d256ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mapping.json\", 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=15, translate= (.15, .15), scale = (0.85, 1.15)),\n",
    "\n",
    "    transforms.Resize(324), \n",
    "    transforms.RandomCrop(299),\n",
    "\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((324, 324)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.TenCrop((299, 299)),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.data[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./dataset',\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "train, test = random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "train_dataset = myDataset(train, transform=train_transform)\n",
    "test_dataset = myDataset(test, transform=test_transform)\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False   \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ea196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize an image from train_dataset\n",
    "\n",
    "i = 1135\n",
    "\n",
    "image = train_dataset[i][0].permute(1, 2, 0).numpy()\n",
    "label = mapping[str(train_dataset[i][1]+1)] #+1 is required, because the \"class 1\" in folders, is class 0 when torch loads it\n",
    "\n",
    "print(f\"label: {label} (index - {train_dataset[i][1]+1})\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNConv2D(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            stride = 1,\n",
    "            padding= 0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        out = self.conv(X)\n",
    "        out = self.bn(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class BN_DepthwiseSeparableConv2D(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            stride = 1,\n",
    "            padding= 0,\n",
    "            dilation=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depthwise_conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels, \n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=in_channels,\n",
    "            bias=False\n",
    "        )\n",
    "        self.pointwise_conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, X):\n",
    "\n",
    "        out = self.depthwise_conv(X)\n",
    "        out = self.pointwise_conv(out)\n",
    "        out = self.bn(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, channels:int=728):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ReLU(), BN_DepthwiseSeparableConv2D(channels, channels, 3, padding=1),\n",
    "            nn.ReLU(), BN_DepthwiseSeparableConv2D(channels, channels, 3, padding=1),\n",
    "            nn.ReLU(), BN_DepthwiseSeparableConv2D(channels, channels, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        out = self.main(X)\n",
    "        out += X\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Xception(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes:int=1000, pretrained=False, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "        \n",
    "        ## ENTRY FLOW\n",
    "        self.block1_conv1 = BNConv2D(in_channels=3, out_channels=32, stride=2, kernel_size=3, padding=0)\n",
    "        self.block1_conv2 = BNConv2D(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        self.residual1 = BNConv2D(in_channels=64, out_channels=128, kernel_size=1, padding=0, stride=2)\n",
    "        self.block2_conv1 = BN_DepthwiseSeparableConv2D(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.block2_conv2 = BN_DepthwiseSeparableConv2D(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "\n",
    "        self.residual2 = BNConv2D(in_channels=128, out_channels=256, kernel_size=1, padding=0, stride=2)\n",
    "        self.block3_conv1 = BN_DepthwiseSeparableConv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.block3_conv2 = BN_DepthwiseSeparableConv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.residual3 = BNConv2D(in_channels=256, out_channels=728, kernel_size=1, padding=0, stride=2)\n",
    "        self.block4_conv1 = BN_DepthwiseSeparableConv2D(in_channels=256, out_channels=728, kernel_size=3, padding=1)\n",
    "        self.block4_conv2 = BN_DepthwiseSeparableConv2D(in_channels=728, out_channels=728, kernel_size=3, padding=1)\n",
    "\n",
    "        ## MIDDLE FLOW\n",
    "        middle_layers = []\n",
    "\n",
    "        for _ in range(8):\n",
    "            middle_layers.append(MiddleBlock())\n",
    "\n",
    "        self.middle_layers = nn.Sequential(*middle_layers)\n",
    "\n",
    "        \n",
    "        ## EXIT FLOW\n",
    "\n",
    "        self.exit_residual = BNConv2D(728, 1024, 1, 2)\n",
    "\n",
    "        self.exitblock1_conv1 = BN_DepthwiseSeparableConv2D(728, 728, 3, padding=1)\n",
    "        self.exitblock1_conv2 = BN_DepthwiseSeparableConv2D(728, 1024, 3, padding=1)\n",
    "\n",
    "        self.exitblock2_conv1 = BN_DepthwiseSeparableConv2D(1024, 1536, 3, padding=1)\n",
    "        self.exitblock2_conv2 = BN_DepthwiseSeparableConv2D(1536, 2048, 3, padding=1)\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(2048, 1000)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpooling = nn.MaxPool2d(3, 2, 1)\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "        if pretrained:\n",
    "            self.load_state_dict(torch.load(\"xception_base.pt\"))\n",
    "        else:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if num_classes!=1000:\n",
    "            self.fc = nn.Linear(2048, num_classes)\n",
    "            \n",
    "            \n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "\n",
    "        ## ENTRY FLow\n",
    "        out = self.block1_conv1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.block1_conv2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        residue = self.residual1(out)\n",
    "        out = self.block2_conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.block2_conv2(out)\n",
    "        out = self.maxpooling(out)\n",
    "        out += residue\n",
    "\n",
    "        residue = self.residual2(out)\n",
    "        out = self.block3_conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.block3_conv2(out)\n",
    "        out = self.maxpooling(out)\n",
    "        out += residue\n",
    "\n",
    "        residue = self.residual3(out)\n",
    "        out = self.block4_conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.block4_conv2(out)\n",
    "        out = self.maxpooling(out)\n",
    "        out += residue\n",
    "\n",
    "        ## MIDDLE FLOW\n",
    "        out = self.middle_layers(out)\n",
    "\n",
    "        ## EXIT FLOW\n",
    "\n",
    "        residue = self.exit_residual(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.exitblock1_conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.exitblock1_conv2(out)\n",
    "        out = self.maxpooling(out)\n",
    "        out += residue\n",
    "\n",
    "        out = self.exitblock2_conv1(out)\n",
    "        out = self.exitblock2_conv2(out)\n",
    "        out = self.global_avgpool(out)\n",
    "\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(2048, 256)\n",
    "nn.init.kaiming_normal_(model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "nn.init.zeros_(model.fc.bias)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n",
    "assert sum(p.numel() for p in model.parameters() if p.requires_grad)==524544\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    start = time.time()\n",
    "    total_training_loss = 0\n",
    "    total_training_samples = 0\n",
    "    total_training_correct_classfied = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    model.fc.train()\n",
    "\n",
    "    for iteration, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output_predictions = model(images)\n",
    "\n",
    "        loss_value = criterion(output_predictions, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        total_training_loss += loss_value.item()*labels.shape[0]\n",
    "        total_training_samples += labels.shape[0]\n",
    "        _, predicted = torch.max(output_predictions, dim=1)\n",
    "        total_training_correct_classfied += (labels == predicted).sum().item()\n",
    "\n",
    "        if iteration%250==0:\n",
    "            print(f\"iteration {iteration+1} done.\")\n",
    "\n",
    "    print(f\"epoch: {epoch+1+0}, train loss: {total_training_loss/total_training_samples}, train accuracy: {total_training_correct_classfied/total_training_samples}, time taken: {time.time()-start}\")\n",
    "\n",
    "    # if (epoch-1)%3==0:\n",
    "    #     print_test_details(model, criterion, test_loader)   \n",
    "    print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39b3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c97ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_new_mapping = {\n",
    "    \"conv1.weight\": \"block1_conv1.conv.weight\",\n",
    "\"bn1.weight\": \"block1_conv1.bn.weight\",\n",
    "\"bn1.bias\": \"block1_conv1.bn.bias\",\n",
    "\"bn1.running_mean\": \"block1_conv1.bn.running_mean\",\n",
    "\"bn1.running_var\": \"block1_conv1.bn.running_var\",\n",
    "\"bn1.num_batches_tracked\": \"block1_conv1.bn.num_batches_tracked\",\n",
    "\"conv2.weight\": \"block1_conv2.conv.weight\",\n",
    "\"bn2.weight\": \"block1_conv2.bn.weight\",\n",
    "\"bn2.bias\": \"block1_conv2.bn.bias\",\n",
    "\"bn2.running_mean\": \"block1_conv2.bn.running_mean\",\n",
    "\"bn2.running_var\": \"block1_conv2.bn.running_var\",\n",
    "\"bn2.num_batches_tracked\": \"block1_conv2.bn.num_batches_tracked\",\n",
    "\"block1.skip.weight\": \"residual1.conv.weight\",\n",
    "\"block1.skipbn.weight\": \"residual1.bn.weight\",\n",
    "\"block1.skipbn.bias\": \"residual1.bn.bias\",\n",
    "\"block1.skipbn.running_mean\": \"residual1.bn.running_mean\",\n",
    "\"block1.skipbn.running_var\": \"residual1.bn.running_var\",\n",
    "\"block1.skipbn.num_batches_tracked\": \"residual1.bn.num_batches_tracked\",\n",
    "\"block1.rep.0.conv1.weight\": \"block2_conv1.depthwise_conv.weight\",\n",
    "\"block1.rep.0.pointwise.weight\": \"block2_conv1.pointwise_conv.weight\",\n",
    "\"block1.rep.1.weight\": \"block2_conv1.bn.weight\",\n",
    "\"block1.rep.1.bias\": \"block2_conv1.bn.bias\",\n",
    "\"block1.rep.1.running_mean\": \"block2_conv1.bn.running_mean\",\n",
    "\"block1.rep.1.running_var\": \"block2_conv1.bn.running_var\",\n",
    "\"block1.rep.1.num_batches_tracked\": \"block2_conv1.bn.num_batches_tracked\",\n",
    "\"block1.rep.3.conv1.weight\": \"block2_conv2.depthwise_conv.weight\",\n",
    "\"block1.rep.3.pointwise.weight\": \"block2_conv2.pointwise_conv.weight\",\n",
    "\"block1.rep.4.weight\": \"block2_conv2.bn.weight\",\n",
    "\"block1.rep.4.bias\": \"block2_conv2.bn.bias\",\n",
    "\"block1.rep.4.running_mean\": \"block2_conv2.bn.running_mean\",\n",
    "\"block1.rep.4.running_var\": \"block2_conv2.bn.running_var\",\n",
    "\"block1.rep.4.num_batches_tracked\": \"block2_conv2.bn.num_batches_tracked\",\n",
    "\"block2.skip.weight\": \"residual2.conv.weight\",\n",
    "\"block2.skipbn.weight\": \"residual2.bn.weight\",\n",
    "\"block2.skipbn.bias\": \"residual2.bn.bias\",\n",
    "\"block2.skipbn.running_mean\": \"residual2.bn.running_mean\",\n",
    "\"block2.skipbn.running_var\": \"residual2.bn.running_var\",\n",
    "\"block2.skipbn.num_batches_tracked\": \"residual2.bn.num_batches_tracked\",\n",
    "\"block2.rep.1.conv1.weight\": \"block3_conv1.depthwise_conv.weight\",\n",
    "\"block2.rep.1.pointwise.weight\": \"block3_conv1.pointwise_conv.weight\",\n",
    "\"block2.rep.2.weight\": \"block3_conv1.bn.weight\",\n",
    "\"block2.rep.2.bias\": \"block3_conv1.bn.bias\",\n",
    "\"block2.rep.2.running_mean\": \"block3_conv1.bn.running_mean\",\n",
    "\"block2.rep.2.running_var\": \"block3_conv1.bn.running_var\",\n",
    "\"block2.rep.2.num_batches_tracked\": \"block3_conv1.bn.num_batches_tracked\",\n",
    "\"block2.rep.4.conv1.weight\": \"block3_conv2.depthwise_conv.weight\",\n",
    "\"block2.rep.4.pointwise.weight\": \"block3_conv2.pointwise_conv.weight\",\n",
    "\"block2.rep.5.weight\": \"block3_conv2.bn.weight\",\n",
    "\"block2.rep.5.bias\": \"block3_conv2.bn.bias\",\n",
    "\"block2.rep.5.running_mean\": \"block3_conv2.bn.running_mean\",\n",
    "\"block2.rep.5.running_var\": \"block3_conv2.bn.running_var\",\n",
    "\"block2.rep.5.num_batches_tracked\": \"block3_conv2.bn.num_batches_tracked\",\n",
    "\"block3.skip.weight\": \"residual3.conv.weight\",\n",
    "\"block3.skipbn.weight\": \"residual3.bn.weight\",\n",
    "\"block3.skipbn.bias\": \"residual3.bn.bias\",\n",
    "\"block3.skipbn.running_mean\": \"residual3.bn.running_mean\",\n",
    "\"block3.skipbn.running_var\": \"residual3.bn.running_var\",\n",
    "\"block3.skipbn.num_batches_tracked\": \"residual3.bn.num_batches_tracked\",\n",
    "\"block3.rep.1.conv1.weight\": \"block4_conv1.depthwise_conv.weight\",\n",
    "\"block3.rep.1.pointwise.weight\": \"block4_conv1.pointwise_conv.weight\",\n",
    "\"block3.rep.2.weight\": \"block4_conv1.bn.weight\",\n",
    "\"block3.rep.2.bias\": \"block4_conv1.bn.bias\",\n",
    "\"block3.rep.2.running_mean\": \"block4_conv1.bn.running_mean\",\n",
    "\"block3.rep.2.running_var\": \"block4_conv1.bn.running_var\",\n",
    "\"block3.rep.2.num_batches_tracked\": \"block4_conv1.bn.num_batches_tracked\",\n",
    "\"block3.rep.4.conv1.weight\": \"block4_conv2.depthwise_conv.weight\",\n",
    "\"block3.rep.4.pointwise.weight\": \"block4_conv2.pointwise_conv.weight\",\n",
    "\"block3.rep.5.weight\": \"block4_conv2.bn.weight\",\n",
    "\"block3.rep.5.bias\": \"block4_conv2.bn.bias\",\n",
    "\"block3.rep.5.running_mean\": \"block4_conv2.bn.running_mean\",\n",
    "\"block3.rep.5.running_var\": \"block4_conv2.bn.running_var\",\n",
    "\"block3.rep.5.num_batches_tracked\": \"block4_conv2.bn.num_batches_tracked\",\n",
    "\"block4.rep.1.conv1.weight\": \"middle_layers.0.main.1.depthwise_conv.weight\",\n",
    "\"block4.rep.1.pointwise.weight\": \"middle_layers.0.main.1.pointwise_conv.weight\",\n",
    "\"block4.rep.2.weight\": \"middle_layers.0.main.1.bn.weight\",\n",
    "\"block4.rep.2.bias\": \"middle_layers.0.main.1.bn.bias\",\n",
    "\"block4.rep.2.running_mean\": \"middle_layers.0.main.1.bn.running_mean\",\n",
    "\"block4.rep.2.running_var\": \"middle_layers.0.main.1.bn.running_var\",\n",
    "\"block4.rep.2.num_batches_tracked\": \"middle_layers.0.main.1.bn.num_batches_tracked\",\n",
    "\"block4.rep.4.conv1.weight\": \"middle_layers.0.main.3.depthwise_conv.weight\",\n",
    "\"block4.rep.4.pointwise.weight\": \"middle_layers.0.main.3.pointwise_conv.weight\",\n",
    "\"block4.rep.5.weight\": \"middle_layers.0.main.3.bn.weight\",\n",
    "\"block4.rep.5.bias\": \"middle_layers.0.main.3.bn.bias\",\n",
    "\"block4.rep.5.running_mean\": \"middle_layers.0.main.3.bn.running_mean\",\n",
    "\"block4.rep.5.running_var\": \"middle_layers.0.main.3.bn.running_var\",\n",
    "\"block4.rep.5.num_batches_tracked\": \"middle_layers.0.main.3.bn.num_batches_tracked\",\n",
    "\"block4.rep.7.conv1.weight\": \"middle_layers.0.main.5.depthwise_conv.weight\",\n",
    "\"block4.rep.7.pointwise.weight\": \"middle_layers.0.main.5.pointwise_conv.weight\",\n",
    "\"block4.rep.8.weight\": \"middle_layers.0.main.5.bn.weight\",\n",
    "\"block4.rep.8.bias\": \"middle_layers.0.main.5.bn.bias\",\n",
    "\"block4.rep.8.running_mean\": \"middle_layers.0.main.5.bn.running_mean\",\n",
    "\"block4.rep.8.running_var\": \"middle_layers.0.main.5.bn.running_var\",\n",
    "\"block4.rep.8.num_batches_tracked\": \"middle_layers.0.main.5.bn.num_batches_tracked\",\n",
    "\"block5.rep.1.conv1.weight\": \"middle_layers.1.main.1.depthwise_conv.weight\",\n",
    "\"block5.rep.1.pointwise.weight\": \"middle_layers.1.main.1.pointwise_conv.weight\",\n",
    "\"block5.rep.2.weight\": \"middle_layers.1.main.1.bn.weight\",\n",
    "\"block5.rep.2.bias\": \"middle_layers.1.main.1.bn.bias\",\n",
    "\"block5.rep.2.running_mean\": \"middle_layers.1.main.1.bn.running_mean\",\n",
    "\"block5.rep.2.running_var\": \"middle_layers.1.main.1.bn.running_var\",\n",
    "\"block5.rep.2.num_batches_tracked\": \"middle_layers.1.main.1.bn.num_batches_tracked\",\n",
    "\"block5.rep.4.conv1.weight\": \"middle_layers.1.main.3.depthwise_conv.weight\",\n",
    "\"block5.rep.4.pointwise.weight\": \"middle_layers.1.main.3.pointwise_conv.weight\",\n",
    "\"block5.rep.5.weight\": \"middle_layers.1.main.3.bn.weight\",\n",
    "\"block5.rep.5.bias\": \"middle_layers.1.main.3.bn.bias\",\n",
    "\"block5.rep.5.running_mean\": \"middle_layers.1.main.3.bn.running_mean\",\n",
    "\"block5.rep.5.running_var\": \"middle_layers.1.main.3.bn.running_var\",\n",
    "\"block5.rep.5.num_batches_tracked\": \"middle_layers.1.main.3.bn.num_batches_tracked\",\n",
    "\"block5.rep.7.conv1.weight\": \"middle_layers.1.main.5.depthwise_conv.weight\",\n",
    "\"block5.rep.7.pointwise.weight\": \"middle_layers.1.main.5.pointwise_conv.weight\",\n",
    "\"block5.rep.8.weight\": \"middle_layers.1.main.5.bn.weight\",\n",
    "\"block5.rep.8.bias\": \"middle_layers.1.main.5.bn.bias\",\n",
    "\"block5.rep.8.running_mean\": \"middle_layers.1.main.5.bn.running_mean\",\n",
    "\"block5.rep.8.running_var\": \"middle_layers.1.main.5.bn.running_var\",\n",
    "\"block5.rep.8.num_batches_tracked\": \"middle_layers.1.main.5.bn.num_batches_tracked\",\n",
    "\"block6.rep.1.conv1.weight\": \"middle_layers.2.main.1.depthwise_conv.weight\",\n",
    "\"block6.rep.1.pointwise.weight\": \"middle_layers.2.main.1.pointwise_conv.weight\",\n",
    "\"block6.rep.2.weight\": \"middle_layers.2.main.1.bn.weight\",\n",
    "\"block6.rep.2.bias\": \"middle_layers.2.main.1.bn.bias\",\n",
    "\"block6.rep.2.running_mean\": \"middle_layers.2.main.1.bn.running_mean\",\n",
    "\"block6.rep.2.running_var\": \"middle_layers.2.main.1.bn.running_var\",\n",
    "\"block6.rep.2.num_batches_tracked\": \"middle_layers.2.main.1.bn.num_batches_tracked\",\n",
    "\"block6.rep.4.conv1.weight\": \"middle_layers.2.main.3.depthwise_conv.weight\",\n",
    "\"block6.rep.4.pointwise.weight\": \"middle_layers.2.main.3.pointwise_conv.weight\",\n",
    "\"block6.rep.5.weight\": \"middle_layers.2.main.3.bn.weight\",\n",
    "\"block6.rep.5.bias\": \"middle_layers.2.main.3.bn.bias\",\n",
    "\"block6.rep.5.running_mean\": \"middle_layers.2.main.3.bn.running_mean\",\n",
    "\"block6.rep.5.running_var\": \"middle_layers.2.main.3.bn.running_var\",\n",
    "\"block6.rep.5.num_batches_tracked\": \"middle_layers.2.main.3.bn.num_batches_tracked\",\n",
    "\"block6.rep.7.conv1.weight\": \"middle_layers.2.main.5.depthwise_conv.weight\",\n",
    "\"block6.rep.7.pointwise.weight\": \"middle_layers.2.main.5.pointwise_conv.weight\",\n",
    "\"block6.rep.8.weight\": \"middle_layers.2.main.5.bn.weight\",\n",
    "\"block6.rep.8.bias\": \"middle_layers.2.main.5.bn.bias\",\n",
    "\"block6.rep.8.running_mean\": \"middle_layers.2.main.5.bn.running_mean\",\n",
    "\"block6.rep.8.running_var\": \"middle_layers.2.main.5.bn.running_var\",\n",
    "\"block6.rep.8.num_batches_tracked\": \"middle_layers.2.main.5.bn.num_batches_tracked\",\n",
    "\"block7.rep.1.conv1.weight\": \"middle_layers.3.main.1.depthwise_conv.weight\",\n",
    "\"block7.rep.1.pointwise.weight\": \"middle_layers.3.main.1.pointwise_conv.weight\",\n",
    "\"block7.rep.2.weight\": \"middle_layers.3.main.1.bn.weight\",\n",
    "\"block7.rep.2.bias\": \"middle_layers.3.main.1.bn.bias\",\n",
    "\"block7.rep.2.running_mean\": \"middle_layers.3.main.1.bn.running_mean\",\n",
    "\"block7.rep.2.running_var\": \"middle_layers.3.main.1.bn.running_var\",\n",
    "\"block7.rep.2.num_batches_tracked\": \"middle_layers.3.main.1.bn.num_batches_tracked\",\n",
    "\"block7.rep.4.conv1.weight\": \"middle_layers.3.main.3.depthwise_conv.weight\",\n",
    "\"block7.rep.4.pointwise.weight\": \"middle_layers.3.main.3.pointwise_conv.weight\",\n",
    "\"block7.rep.5.weight\": \"middle_layers.3.main.3.bn.weight\",\n",
    "\"block7.rep.5.bias\": \"middle_layers.3.main.3.bn.bias\",\n",
    "\"block7.rep.5.running_mean\": \"middle_layers.3.main.3.bn.running_mean\",\n",
    "\"block7.rep.5.running_var\": \"middle_layers.3.main.3.bn.running_var\",\n",
    "\"block7.rep.5.num_batches_tracked\": \"middle_layers.3.main.3.bn.num_batches_tracked\",\n",
    "\"block7.rep.7.conv1.weight\": \"middle_layers.3.main.5.depthwise_conv.weight\",\n",
    "\"block7.rep.7.pointwise.weight\": \"middle_layers.3.main.5.pointwise_conv.weight\",\n",
    "\"block7.rep.8.weight\": \"middle_layers.3.main.5.bn.weight\",\n",
    "\"block7.rep.8.bias\": \"middle_layers.3.main.5.bn.bias\",\n",
    "\"block7.rep.8.running_mean\": \"middle_layers.3.main.5.bn.running_mean\",\n",
    "\"block7.rep.8.running_var\": \"middle_layers.3.main.5.bn.running_var\",\n",
    "\"block7.rep.8.num_batches_tracked\": \"middle_layers.3.main.5.bn.num_batches_tracked\",\n",
    "\"block8.rep.1.conv1.weight\": \"middle_layers.4.main.1.depthwise_conv.weight\",\n",
    "\"block8.rep.1.pointwise.weight\": \"middle_layers.4.main.1.pointwise_conv.weight\",\n",
    "\"block8.rep.2.weight\": \"middle_layers.4.main.1.bn.weight\",\n",
    "\"block8.rep.2.bias\": \"middle_layers.4.main.1.bn.bias\",\n",
    "\"block8.rep.2.running_mean\": \"middle_layers.4.main.1.bn.running_mean\",\n",
    "\"block8.rep.2.running_var\": \"middle_layers.4.main.1.bn.running_var\",\n",
    "\"block8.rep.2.num_batches_tracked\": \"middle_layers.4.main.1.bn.num_batches_tracked\",\n",
    "\"block8.rep.4.conv1.weight\": \"middle_layers.4.main.3.depthwise_conv.weight\",\n",
    "\"block8.rep.4.pointwise.weight\": \"middle_layers.4.main.3.pointwise_conv.weight\",\n",
    "\"block8.rep.5.weight\": \"middle_layers.4.main.3.bn.weight\",\n",
    "\"block8.rep.5.bias\": \"middle_layers.4.main.3.bn.bias\",\n",
    "\"block8.rep.5.running_mean\": \"middle_layers.4.main.3.bn.running_mean\",\n",
    "\"block8.rep.5.running_var\": \"middle_layers.4.main.3.bn.running_var\",\n",
    "\"block8.rep.5.num_batches_tracked\": \"middle_layers.4.main.3.bn.num_batches_tracked\",\n",
    "\"block8.rep.7.conv1.weight\": \"middle_layers.4.main.5.depthwise_conv.weight\",\n",
    "\"block8.rep.7.pointwise.weight\": \"middle_layers.4.main.5.pointwise_conv.weight\",\n",
    "\"block8.rep.8.weight\": \"middle_layers.4.main.5.bn.weight\",\n",
    "\"block8.rep.8.bias\": \"middle_layers.4.main.5.bn.bias\",\n",
    "\"block8.rep.8.running_mean\": \"middle_layers.4.main.5.bn.running_mean\",\n",
    "\"block8.rep.8.running_var\": \"middle_layers.4.main.5.bn.running_var\",\n",
    "\"block8.rep.8.num_batches_tracked\": \"middle_layers.4.main.5.bn.num_batches_tracked\",\n",
    "\"block9.rep.1.conv1.weight\": \"middle_layers.5.main.1.depthwise_conv.weight\",\n",
    "\"block9.rep.1.pointwise.weight\": \"middle_layers.5.main.1.pointwise_conv.weight\",\n",
    "\"block9.rep.2.weight\": \"middle_layers.5.main.1.bn.weight\",\n",
    "\"block9.rep.2.bias\": \"middle_layers.5.main.1.bn.bias\",\n",
    "\"block9.rep.2.running_mean\": \"middle_layers.5.main.1.bn.running_mean\",\n",
    "\"block9.rep.2.running_var\": \"middle_layers.5.main.1.bn.running_var\",\n",
    "\"block9.rep.2.num_batches_tracked\": \"middle_layers.5.main.1.bn.num_batches_tracked\",\n",
    "\"block9.rep.4.conv1.weight\": \"middle_layers.5.main.3.depthwise_conv.weight\",\n",
    "\"block9.rep.4.pointwise.weight\": \"middle_layers.5.main.3.pointwise_conv.weight\",\n",
    "\"block9.rep.5.weight\": \"middle_layers.5.main.3.bn.weight\",\n",
    "\"block9.rep.5.bias\": \"middle_layers.5.main.3.bn.bias\",\n",
    "\"block9.rep.5.running_mean\": \"middle_layers.5.main.3.bn.running_mean\",\n",
    "\"block9.rep.5.running_var\": \"middle_layers.5.main.3.bn.running_var\",\n",
    "\"block9.rep.5.num_batches_tracked\": \"middle_layers.5.main.3.bn.num_batches_tracked\",\n",
    "\"block9.rep.7.conv1.weight\": \"middle_layers.5.main.5.depthwise_conv.weight\",\n",
    "\"block9.rep.7.pointwise.weight\": \"middle_layers.5.main.5.pointwise_conv.weight\",\n",
    "\"block9.rep.8.weight\": \"middle_layers.5.main.5.bn.weight\",\n",
    "\"block9.rep.8.bias\": \"middle_layers.5.main.5.bn.bias\",\n",
    "\"block9.rep.8.running_mean\": \"middle_layers.5.main.5.bn.running_mean\",\n",
    "\"block9.rep.8.running_var\": \"middle_layers.5.main.5.bn.running_var\",\n",
    "\"block9.rep.8.num_batches_tracked\": \"middle_layers.5.main.5.bn.num_batches_tracked\",\n",
    "\"block10.rep.1.conv1.weight\": \"middle_layers.6.main.1.depthwise_conv.weight\",\n",
    "\"block10.rep.1.pointwise.weight\": \"middle_layers.6.main.1.pointwise_conv.weight\",\n",
    "\"block10.rep.2.weight\": \"middle_layers.6.main.1.bn.weight\",\n",
    "\"block10.rep.2.bias\": \"middle_layers.6.main.1.bn.bias\",\n",
    "\"block10.rep.2.running_mean\": \"middle_layers.6.main.1.bn.running_mean\",\n",
    "\"block10.rep.2.running_var\": \"middle_layers.6.main.1.bn.running_var\",\n",
    "\"block10.rep.2.num_batches_tracked\": \"middle_layers.6.main.1.bn.num_batches_tracked\",\n",
    "\"block10.rep.4.conv1.weight\": \"middle_layers.6.main.3.depthwise_conv.weight\",\n",
    "\"block10.rep.4.pointwise.weight\": \"middle_layers.6.main.3.pointwise_conv.weight\",\n",
    "\"block10.rep.5.weight\": \"middle_layers.6.main.3.bn.weight\",\n",
    "\"block10.rep.5.bias\": \"middle_layers.6.main.3.bn.bias\",\n",
    "\"block10.rep.5.running_mean\": \"middle_layers.6.main.3.bn.running_mean\",\n",
    "\"block10.rep.5.running_var\": \"middle_layers.6.main.3.bn.running_var\",\n",
    "\"block10.rep.5.num_batches_tracked\": \"middle_layers.6.main.3.bn.num_batches_tracked\",\n",
    "\"block10.rep.7.conv1.weight\": \"middle_layers.6.main.5.depthwise_conv.weight\",\n",
    "\"block10.rep.7.pointwise.weight\": \"middle_layers.6.main.5.pointwise_conv.weight\",\n",
    "\"block10.rep.8.weight\": \"middle_layers.6.main.5.bn.weight\",\n",
    "\"block10.rep.8.bias\": \"middle_layers.6.main.5.bn.bias\",\n",
    "\"block10.rep.8.running_mean\": \"middle_layers.6.main.5.bn.running_mean\",\n",
    "\"block10.rep.8.running_var\": \"middle_layers.6.main.5.bn.running_var\",\n",
    "\"block10.rep.8.num_batches_tracked\": \"middle_layers.6.main.5.bn.num_batches_tracked\",\n",
    "\"block11.rep.1.conv1.weight\": \"middle_layers.7.main.1.depthwise_conv.weight\",\n",
    "\"block11.rep.1.pointwise.weight\": \"middle_layers.7.main.1.pointwise_conv.weight\",\n",
    "\"block11.rep.2.weight\": \"middle_layers.7.main.1.bn.weight\",\n",
    "\"block11.rep.2.bias\": \"middle_layers.7.main.1.bn.bias\",\n",
    "\"block11.rep.2.running_mean\": \"middle_layers.7.main.1.bn.running_mean\",\n",
    "\"block11.rep.2.running_var\": \"middle_layers.7.main.1.bn.running_var\",\n",
    "\"block11.rep.2.num_batches_tracked\": \"middle_layers.7.main.1.bn.num_batches_tracked\",\n",
    "\"block11.rep.4.conv1.weight\": \"middle_layers.7.main.3.depthwise_conv.weight\",\n",
    "\"block11.rep.4.pointwise.weight\": \"middle_layers.7.main.3.pointwise_conv.weight\",\n",
    "\"block11.rep.5.weight\": \"middle_layers.7.main.3.bn.weight\",\n",
    "\"block11.rep.5.bias\": \"middle_layers.7.main.3.bn.bias\",\n",
    "\"block11.rep.5.running_mean\": \"middle_layers.7.main.3.bn.running_mean\",\n",
    "\"block11.rep.5.running_var\": \"middle_layers.7.main.3.bn.running_var\",\n",
    "\"block11.rep.5.num_batches_tracked\": \"middle_layers.7.main.3.bn.num_batches_tracked\",\n",
    "\"block11.rep.7.conv1.weight\": \"middle_layers.7.main.5.depthwise_conv.weight\",\n",
    "\"block11.rep.7.pointwise.weight\": \"middle_layers.7.main.5.pointwise_conv.weight\",\n",
    "\"block11.rep.8.weight\": \"middle_layers.7.main.5.bn.weight\",\n",
    "\"block11.rep.8.bias\": \"middle_layers.7.main.5.bn.bias\",\n",
    "\"block11.rep.8.running_mean\": \"middle_layers.7.main.5.bn.running_mean\",\n",
    "\"block11.rep.8.running_var\": \"middle_layers.7.main.5.bn.running_var\",\n",
    "\"block11.rep.8.num_batches_tracked\": \"middle_layers.7.main.5.bn.num_batches_tracked\",\n",
    "\"block12.skip.weight\": \"exit_residual.conv.weight\",\n",
    "\"block12.skipbn.weight\": \"exit_residual.bn.weight\",\n",
    "\"block12.skipbn.bias\": \"exit_residual.bn.bias\",\n",
    "\"block12.skipbn.running_mean\": \"exit_residual.bn.running_mean\",\n",
    "\"block12.skipbn.running_var\": \"exit_residual.bn.running_var\",\n",
    "\"block12.skipbn.num_batches_tracked\": \"exit_residual.bn.num_batches_tracked\",\n",
    "\"block12.rep.1.conv1.weight\": \"exitblock1_conv1.depthwise_conv.weight\",\n",
    "\"block12.rep.1.pointwise.weight\": \"exitblock1_conv1.pointwise_conv.weight\",\n",
    "\"block12.rep.2.weight\": \"exitblock1_conv1.bn.weight\",\n",
    "\"block12.rep.2.bias\": \"exitblock1_conv1.bn.bias\",\n",
    "\"block12.rep.2.running_mean\": \"exitblock1_conv1.bn.running_mean\",\n",
    "\"block12.rep.2.running_var\": \"exitblock1_conv1.bn.running_var\",\n",
    "\"block12.rep.2.num_batches_tracked\": \"exitblock1_conv1.bn.num_batches_tracked\",\n",
    "\"block12.rep.4.conv1.weight\": \"exitblock1_conv2.depthwise_conv.weight\",\n",
    "\"block12.rep.4.pointwise.weight\": \"exitblock1_conv2.pointwise_conv.weight\",\n",
    "\"block12.rep.5.weight\": \"exitblock1_conv2.bn.weight\",\n",
    "\"block12.rep.5.bias\": \"exitblock1_conv2.bn.bias\",\n",
    "\"block12.rep.5.running_mean\": \"exitblock1_conv2.bn.running_mean\",\n",
    "\"block12.rep.5.running_var\": \"exitblock1_conv2.bn.running_var\",\n",
    "\"block12.rep.5.num_batches_tracked\": \"exitblock1_conv2.bn.num_batches_tracked\",\n",
    "\"conv3.conv1.weight\": \"exitblock2_conv1.depthwise_conv.weight\",\n",
    "\"conv3.pointwise.weight\": \"exitblock2_conv1.pointwise_conv.weight\",\n",
    "\"bn3.weight\": \"exitblock2_conv1.bn.weight\",\n",
    "\"bn3.bias\": \"exitblock2_conv1.bn.bias\",\n",
    "\"bn3.running_mean\": \"exitblock2_conv1.bn.running_mean\",\n",
    "\"bn3.running_var\": \"exitblock2_conv1.bn.running_var\",\n",
    "\"bn3.num_batches_tracked\": \"exitblock2_conv1.bn.num_batches_tracked\",\n",
    "\"conv4.conv1.weight\": \"exitblock2_conv2.depthwise_conv.weight\",\n",
    "\"conv4.pointwise.weight\": \"exitblock2_conv2.pointwise_conv.weight\",\n",
    "\"bn4.weight\": \"exitblock2_conv2.bn.weight\",\n",
    "\"bn4.bias\": \"exitblock2_conv2.bn.bias\",\n",
    "\"bn4.running_mean\": \"exitblock2_conv2.bn.running_mean\",\n",
    "\"bn4.running_var\": \"exitblock2_conv2.bn.running_var\",\n",
    "\"bn4.num_batches_tracked\": \"exitblock2_conv2.bn.num_batches_tracked\",\n",
    "\"fc.weight\": \"fc.weight\",\n",
    "\"fc.bias\": \"fc.bias\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc244f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "waw = BNConv2D(3, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
