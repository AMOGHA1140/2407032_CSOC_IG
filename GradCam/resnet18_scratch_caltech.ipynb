{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e9ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44308902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "train_size = 0.8\n",
    "test_size=0.2\n",
    "device = 'cuda'\n",
    "cpu = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ce1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mapping.json\", 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=15, translate= (.15, .15), scale = (0.85, 1.15)),\n",
    "\n",
    "    transforms.Resize((224,224)), #Resize data to be 224x224.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.TenCrop((224, 224)),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f618263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./dataset',\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.data[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bbf506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320a08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = myDataset(train, transform=train_transform)\n",
    "test_dataset = myDataset(test, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dace667",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fcec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#visualize an image from test_dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m i = \u001b[32m1135\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m image = \u001b[43mtest_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.numpy()\n\u001b[32m      6\u001b[39m label = mapping[\u001b[38;5;28mstr\u001b[39m(test_dataset[i][\u001b[32m1\u001b[39m]+\u001b[32m1\u001b[39m)] \u001b[38;5;66;03m#+1 is required, because the \"class 1\" in folders, is class 0 when torch loads it\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (index - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_dataset[i][\u001b[32m1\u001b[39m]+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "#visualize an image from test_dataset\n",
    "\n",
    "i = 1135\n",
    "\n",
    "image = test_dataset[i][0].permute(1, 2, 0).numpy()\n",
    "label = mapping[str(test_dataset[i][1]+1)] #+1 is required, because the \"class 1\" in folders, is class 0 when torch loads it\n",
    "\n",
    "print(f\"label: {label} (index - {test_dataset[i][1]+1})\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def print_test_details(model:nn.Module, loss, test_loader:torch.utils.data.DataLoader=test_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    top_1_correct = 0\n",
    "    top_5_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for test_features, test_labels in iter(test_loader):\n",
    "\n",
    "        test_features = test_features.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "        size = len(test_features)\n",
    "\n",
    "        model_output:torch.Tensor = model(test_features)\n",
    "        total_loss += loss(model_output, test_labels).item()*size\n",
    "\n",
    "\n",
    "        all_labels = np.array(range(model_output.shape[1]))\n",
    "    \n",
    "        top_1_correct += top_k_accuracy_score(test_labels.to('cpu'), model_output.to('cpu'), k=1, labels=all_labels)*size\n",
    "        top_5_correct += top_k_accuracy_score(test_labels.to('cpu'), model_output.to('cpu'), k=5, labels=all_labels)*size\n",
    "\n",
    "    top_1_accuracy = top_1_correct/len(test_loader.dataset)\n",
    "    top_5_accuracy = top_5_correct/len(test_loader.dataset)\n",
    "    loss_value = total_loss/len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Test Score - Loss: {loss_value}, top-1 accuracy: {top_1_accuracy}, top-5 accuracy: {top_5_accuracy}\")\n",
    "\n",
    "    return (loss_value, top_1_accuracy, top_5_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a68f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels:int, out_channels:int, stride:int=1, padding='valid'):\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels, \n",
    "        out_channels=out_channels, \n",
    "        kernel_size=3,\n",
    "        padding=padding,\n",
    "        stride=stride,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "def conv1x1(in_channels:int, out_channels:int, stride:int=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, ):\n",
    "        pass\n",
    "\n",
    "    def forard(self, X):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torchvision.models.resnet18(num_classes=256)\n",
    "# model.load_state_dict(torch.load(\"resnet18_scratch_weights.pth\"))\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b294443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "\n",
    "    start = time.time()\n",
    "    total_training_loss = 0\n",
    "    total_training_samples = 0\n",
    "    total_training_correct_classfied = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for iteration, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output_predictions = model(images)\n",
    "\n",
    "        loss_value = criterion(output_predictions, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        total_training_loss += loss_value.item()*labels.shape[0]\n",
    "        total_training_samples += labels.shape[0]\n",
    "        _, predicted = torch.max(output_predictions, dim=1)\n",
    "        total_training_correct_classfied += (labels == predicted).sum().item()\n",
    "\n",
    "        if iteration%50==0:\n",
    "            print(f\"iteration {iteration+1} done.\")\n",
    "\n",
    "    print(f\"epoch: {epoch+1}, train loss: {total_training_loss/total_training_samples}, train accuracy: {total_training_correct_classfied/total_training_samples}, time taken: {time.time()-start}\")\n",
    "    print_test_details(model, criterion)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet18_scratch_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_details(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbd073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3446024",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "0) visualize class activation mappings \n",
    "1) Implement resnet-18 from scratch and train it.\n",
    "2) change architecture a bit for resnet-18 and train it again\n",
    "3) implement inception with residual connections and train it.\n",
    "4) make something on your own and train it\n",
    "5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
