{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34298094-9c7a-494b-92d2-f2d154723b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3e61eb-743c-4b63-a11c-538752dce076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"transformed_dataset.csv\")\n",
    "# data['NoShow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0194a4c2-5b0b-436a-a517-0482fa71a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ToTensor:\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if not isinstance(data, tuple):\n",
    "            return torch.from_numpy(data)\n",
    "        X, y = data\n",
    "        return torch.from_numpy(X), torch.from_numpy(y)\n",
    "\n",
    "\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, transforms=None):\n",
    "        data = pd.read_csv(\"transformed_dataset.csv\")\n",
    "        self.X = data.drop(columns=['NoShow']).to_numpy(dtype=np.float32)\n",
    "        self.y = data['NoShow'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.X[index], self.y[index]\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.5, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        #input is logits, before applying sigmoid\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "\n",
    "        focal_loss = (1-p_t)**self.gamma * bce_loss\n",
    "\n",
    "        weights = self.alpha*targets  + (1-self.alpha)*(1-targets)\n",
    "        weights = weights.to(focal_loss.device)\n",
    "\n",
    "        return (focal_loss*weights).mean()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6c1c3002-03a4-45bd-ab41-e8a18730ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyData(transforms=ToTensor())\n",
    "\n",
    "input_size = data[0][0].shape[0] #first training example, get features, then get number of features\n",
    "output_size= 1\n",
    "\n",
    "train, test = random_split(data, [0.7, 0.3])\n",
    "train_loader = DataLoader(train, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "# data[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4cc485e0-4cf7-4b12-bc71-ef6c5dadcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, 64),\n",
    "    # nn.Dropout(p=0.4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    # nn.Dropout(p=0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    ")\n",
    "\n",
    "# loss = nn.BCEWithLogitsLoss(weight=torch.Tensor([3.0]))\n",
    "loss = FocalLoss(alpha=0.6, gamma=2.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ccef4fac-d19b-4e6b-917f-8031142c7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cuda')\n",
    "# loss = loss.to('cuda')\n",
    "# # optimizer = optimizer.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "579e0808-e781-4a6a-bab6-0d7a8669e813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, iteration: 1, loss: 0.0650, Test PR-AUC: 0.5996, max-f1: 0.3323\n",
      "Epoch: 1, iteration: 51, loss: 0.0672, Test PR-AUC: 0.5996, max-f1: 0.3323\n",
      "overall epoch 1 loss: 0.0670233459273974\n",
      "Epoch: 2, iteration: 1, loss: 0.0657, Test PR-AUC: 0.5996, max-f1: 0.3323\n",
      "Epoch: 2, iteration: 51, loss: 0.0634, Test PR-AUC: 0.5996, max-f1: 0.3323\n",
      "overall epoch 2 loss: 0.06700796609123548\n",
      "Epoch: 3, iteration: 1, loss: 0.0663, Test PR-AUC: 0.5996, max-f1: 0.3323\n",
      "Epoch: 3, iteration: 51, loss: 0.0682, Test PR-AUC: 0.5996, max-f1: 0.3323\n",
      "overall epoch 3 loss: 0.06700376590092977\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    total_training_loss = 0\n",
    "    \n",
    "    for iteration, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        output = model(features)\n",
    "        loss_value = loss(output, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_training_loss += loss_value.item()\n",
    "\n",
    "        if (iteration%50==0):\n",
    "            x_test, y_test = next(iter(test_loader))\n",
    "            with torch.no_grad():\n",
    "                test_output = torch.sigmoid(model(x_test))\n",
    "                \n",
    "            precision, recall, thresholds = precision_recall_curve(y_test, test_output)\n",
    "            # print(f\"\")\n",
    "            maxf1 = 2*np.max(precision*recall/(precision+recall+1e-9))\n",
    "            \n",
    "            \n",
    "            print(f\"Epoch: {epoch+1}, iteration: {iteration+1}, loss: {loss_value.item():.4f}, Test PR-AUC: {auc(recall, precision):.4f}, max-f1: {maxf1:.4f}\")\n",
    "            \n",
    "\n",
    "    print(f\"overall epoch {epoch+1} loss: {total_training_loss/iteration}\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "00878fae-3298-4cc1-b377-b7abd005a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max- 0.7034276760011564\n",
      "0.4321233976729597\n",
      "0.3071265445367033\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output = torch.sigmoid(model(x_test))\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.cpu(), test_output.cpu())\n",
    "    print(\"max-\", f1_score(y_test.cpu(), (test_output>0.5).cpu(), average='weighted'))\n",
    "            \n",
    "    # print(f\"\")\n",
    "    maxf1 = 2*np.max(precision*recall/(precision+recall+1e-9))\n",
    "    print(maxf1)\n",
    "    print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7ac1066-72f6-459a-862e-72d88bcff07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n",
    "\n",
    "# f1_score(y_test, y_pred>=0.365, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000ac774-59ed-4a3b-b74e-eb79aa8e689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14527045632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory().used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "109577fd-cecc-4dcf-b4d2-0aef61b7be46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8b2736-f219-4481-b2fd-5a790ab1abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current script - RSS: 629.91 MB\n",
      "Current script - VMS: 1796.74 MB\n",
      "Total system RAM used: 13.53 GB\n"
     ]
    }
   ],
   "source": [
    "### THIS PART OF CODE WAS GENERATED USING GEMINI\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Get the current process\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "# Get memory info for this specific process\n",
    "# .rss (Resident Set Size) is often a good measure for actual physical RAM used by the process.\n",
    "# .vms (Virtual Memory Size) is the total virtual address space, can be much larger.\n",
    "mem_info = process.memory_info()\n",
    "rss_bytes = mem_info.rss\n",
    "vms_bytes = mem_info.vms\n",
    "\n",
    "print(f\"Current script - RSS: {rss_bytes / (1024 * 1024):.2f} MB\") # Resident Set Size\n",
    "print(f\"Current script - VMS: {vms_bytes / (1024 * 1024):.2f} MB\") # Virtual Memory Size\n",
    "\n",
    "# For total system usage (what you were using before)\n",
    "total_system_used_bytes = psutil.virtual_memory().used\n",
    "print(f\"Total system RAM used: {total_system_used_bytes / (1024 * 1024 * 1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3527d-d1bd-4fc1-ae07-5eeaa0b5828b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
